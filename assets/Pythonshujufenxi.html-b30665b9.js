import{_ as o,r as i,o as p,c as l,a as s,b as n,d as t,e as a}from"./app-d188f79b.js";const c={},u=a('<p>没想到这么快就大三了，不考虑考研的话今年暑假该实习了。本来想着在国庆前将前面学的全部梳理一下（其实这原本是暑假的明目标），然后这一年全力准备实习。没想到开学就来了个短学期😕，不过也好做个项目也可以检验自己的水平。虽然时间有点短项目有点小很多东西来不及做，但我还是尽量把能用上的用上。</p><p>通过此次实践可以巩固以下几个技术：</p><ul><li>数据分析</li><li>爬虫</li><li>可视化交互（这次时间较短所以没有使用前端技术，主要使用 Python 实现）</li><li>Linux 部署项目</li><li>Git 版本控制</li></ul><p>废话不多说，下面开始：</p><h2 id="背景" tabindex="-1"><a class="header-anchor" href="#背景" aria-hidden="true">#</a> 背景</h2><p>基于阿里云天池提供的 arXiv 中公开的论文数据集, 通过数据分析研究学术发展趋势。</p>',6),r={href:"https://www.aliyundrive.com/s/AVwCUPR2rMV",target:"_blank",rel:"noopener noreferrer"},d=a('<h2 id="前期准备" tabindex="-1"><a class="header-anchor" href="#前期准备" aria-hidden="true">#</a> 前期准备</h2><h3 id="需求分析" tabindex="-1"><a class="header-anchor" href="#需求分析" aria-hidden="true">#</a> 需求分析</h3><p>先建立大致分析目标，后续再慢慢调整：</p><ol><li>每种类型论文数量</li><li>按月份统计每个月论文的提交数量</li><li>论文摘要和论文标题出现关键词的频率</li><li>论文更新次数</li><li>论文作者关系（联通图）</li><li>作者的论文个数排行</li><li>页数、图、表统计</li></ol><h3 id="json文件分析" tabindex="-1"><a class="header-anchor" href="#json文件分析" aria-hidden="true">#</a> json文件分析</h3>',5),k={href:"https://www.bejson.com/jsonviewernew/",target:"_blank",rel:"noopener noreferrer"},v=a(`<div class="language-json line-numbers-mode" data-ext="json"><pre class="language-json"><code><span class="token punctuation">{</span>
  <span class="token property">&quot;id&quot;</span><span class="token operator">:</span> <span class="token string">&quot;0704.0297&quot;</span><span class="token punctuation">,</span>
  <span class="token property">&quot;submitter&quot;</span><span class="token operator">:</span> <span class="token string">&quot;Sung-Chul Yoon&quot;</span><span class="token punctuation">,</span>
  <span class="token property">&quot;authors&quot;</span><span class="token operator">:</span> <span class="token string">&quot;Sung-Chul Yoon, Philipp Podsiadlowski and Stephan Rosswog&quot;</span><span class="token punctuation">,</span>
  <span class="token property">&quot;title&quot;</span><span class="token operator">:</span> <span class="token string">&quot;Remnant evolution after a carbon-oxygen white dwarf merger&quot;</span><span class="token punctuation">,</span>
  <span class="token property">&quot;comments&quot;</span><span class="token operator">:</span> <span class="token string">&quot;15 pages, 15 figures, 3 tables, submitted to MNRAS (Low resolution\\n  version; a high resolution version can be found at:\\n  http://www.astro.uva.nl/~scyoon/papers/wdmerger.pdf)&quot;</span><span class="token punctuation">,</span>
  <span class="token property">&quot;journal-ref&quot;</span><span class="token operator">:</span> <span class="token null keyword">null</span><span class="token punctuation">,</span>
  <span class="token property">&quot;doi&quot;</span><span class="token operator">:</span> <span class="token string">&quot;10.1111/j.1365-2966.2007.12161.x&quot;</span><span class="token punctuation">,</span>
  <span class="token property">&quot;report-no&quot;</span><span class="token operator">:</span> <span class="token null keyword">null</span><span class="token punctuation">,</span>
  <span class="token property">&quot;categories&quot;</span><span class="token operator">:</span> <span class="token string">&quot;astro-ph&quot;</span><span class="token punctuation">,</span>
  <span class="token property">&quot;license&quot;</span><span class="token operator">:</span> <span class="token null keyword">null</span><span class="token punctuation">,</span>
  <span class="token property">&quot;abstract&quot;</span><span class="token operator">:</span> <span class="token string">&quot;  We systematically explore the evolution of the merger of two carbon-oxygen\\n(CO) white dwarfs. The dynamical evolution of a 0.9 Msun + 0.6 Msun CO white\\ndwarf merger is followed by a three-dimensional SPH simulation. We use an\\nelaborate prescription in which artificial viscosity is essentially absent,\\nunless a shock is detected, and a much larger number of SPH particles than\\nearlier calculations. Based on this simulation, we suggest that the central\\nregion of the merger remnant can, once it has reached quasi-static equilibrium,\\nbe approximated as a differentially rotating CO star, which consists of a\\nslowly rotating cold core and a rapidly rotating hot envelope surrounded by a\\ncentrifugally supported disc. We construct a model of the CO remnant that\\nmimics the results of the SPH simulation using a one-dimensional hydrodynamic\\nstellar evolution code and then follow its secular evolution. The stellar\\nevolution models indicate that the growth of the cold core is controlled by\\nneutrino cooling at the interface between the core and the hot envelope, and\\nthat carbon ignition in the envelope can be avoided despite high effective\\naccretion rates. This result suggests that the assumption of forced accretion\\nof cold matter that was adopted in previous studies of the evolution of double\\nCO white dwarf merger remnants may not be appropriate. Our results imply that\\nat least some products of double CO white dwarfs merger may be considered good\\ncandidates for the progenitors of Type Ia supernovae. In this case, the\\ncharacteristic time delay between the initial dynamical merger and the eventual\\nexplosion would be ~10^5 yr. (Abridged).\\n&quot;</span><span class="token punctuation">,</span>
  <span class="token property">&quot;versions&quot;</span><span class="token operator">:</span> <span class="token punctuation">[</span>
    <span class="token punctuation">{</span>
      <span class="token property">&quot;version&quot;</span><span class="token operator">:</span> <span class="token string">&quot;v1&quot;</span><span class="token punctuation">,</span>
      <span class="token property">&quot;created&quot;</span><span class="token operator">:</span> <span class="token string">&quot;Tue, 3 Apr 2007 01:50:26 GMT&quot;</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">{</span>
      <span class="token property">&quot;version&quot;</span><span class="token operator">:</span> <span class="token string">&quot;v2&quot;</span><span class="token punctuation">,</span>
      <span class="token property">&quot;created&quot;</span><span class="token operator">:</span> <span class="token string">&quot;Wed, 4 Apr 2007 17:28:44 GMT&quot;</span>
    <span class="token punctuation">}</span>
  <span class="token punctuation">]</span><span class="token punctuation">,</span>
  <span class="token property">&quot;update_date&quot;</span><span class="token operator">:</span> <span class="token string">&quot;2019-08-19&quot;</span><span class="token punctuation">,</span>
  <span class="token property">&quot;authors_parsed&quot;</span><span class="token operator">:</span> <span class="token punctuation">[</span>
    <span class="token punctuation">[</span>
      <span class="token string">&quot;Yoon&quot;</span><span class="token punctuation">,</span>
      <span class="token string">&quot;Sung-Chul&quot;</span><span class="token punctuation">,</span>
      <span class="token string">&quot;&quot;</span>
    <span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token punctuation">[</span>
      <span class="token string">&quot;Podsiadlowski&quot;</span><span class="token punctuation">,</span>
      <span class="token string">&quot;Philipp&quot;</span><span class="token punctuation">,</span>
      <span class="token string">&quot;&quot;</span>
    <span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token punctuation">[</span>
      <span class="token string">&quot;Rosswog&quot;</span><span class="token punctuation">,</span>
      <span class="token string">&quot;Stephan&quot;</span><span class="token punctuation">,</span>
      <span class="token string">&quot;&quot;</span>
    <span class="token punctuation">]</span>
  <span class="token punctuation">]</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>字段分析：</p>`,2),m=a("<li><code>id</code>：arXiv ID，可用于访问论文</li><li><code>submitter</code>：论文提交者</li><li><code>authors</code>：论文作者 4</li><li><code>title</code>：文标题</li><li><code>comments</code>：论文页数和图表等其他信息 4</li><li><code>journal-ref</code>：论文发表的期刊的信息</li>",6),h=s("code",null,"doi",-1),b={href:"https://www.doi.org",target:"_blank",rel:"noopener noreferrer"},g=a("<li><code>report-no</code>：报告编号</li><li><code>categories</code>：论文在 arXiv 系统的所属类别或标签</li><li><code>license</code>：文章的许可证</li><li><code>abstract</code>：论文摘要</li><li><code>versions</code>：论文版本</li><li><code>authors_parsed</code>：作者的信息</li>",6),q=s("code",null,"categories",-1),y={href:"https://arxiv.org/category_taxonomy",target:"_blank",rel:"noopener noreferrer"},_=s("code",null,"Computer Science",-1),f=s("code",null,"Economics",-1),w=s("code",null,"Electrical Engineering and Systems Science、",-1),x=s("code",null,"Mathematics",-1),j=s("code",null,"Physics",-1),S=s("code",null,"Quantitative Biology",-1),P=s("code",null,"Quantitative Finance",-1),C=s("code",null,"Statistics",-1),A=a('<p>爬虫：</p><ol><li>request 库发送网络请求获取网页数据。</li><li>bs4库解析网页文件，提取数据。此外，还可以使用Xpath解析或者使用正则表达式。使用bs4因为语法简单。但是，这个只适用Python。</li></ol><h3 id="技术选型" tabindex="-1"><a class="header-anchor" href="#技术选型" aria-hidden="true">#</a> 技术选型</h3><ol><li><p>数据分析 Pandas</p></li><li><p>request、bs4 爬虫</p></li><li><p>Streamlit + plotly + Altair + pyecharts 可视化</p><p>原因：</p><ol><li>可以实现交互</li><li>不需要编写前端代码，开发速度快</li><li>文档丰富</li></ol></li></ol><h3 id="开发工具" tabindex="-1"><a class="header-anchor" href="#开发工具" aria-hidden="true">#</a> 开发工具</h3><ol><li>PyCharm</li><li>Jupyter notebook</li></ol><h2 id="第一个目标-每种类型论文数量" tabindex="-1"><a class="header-anchor" href="#第一个目标-每种类型论文数量" aria-hidden="true">#</a> 第一个目标：每种类型论文数量</h2>',7),T={href:"https://arxiv.org/category_taxonomy",target:"_blank",rel:"noopener noreferrer"},M=s("code",null,'"categories": "astro-ph"',-1),E=s("code",null,"pandas",-1),O=a(`<div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">queryBycategrot</span><span class="token punctuation">(</span>data<span class="token punctuation">,</span> categrot<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">&quot;&quot;&quot;
    根据类别查询数据的函数。

    参数：
        - data：要查询的数据。
        - categrot：要按照的类别进行过滤的字符串。

    返回：
        - 根据指定类别过滤后的数据。
    &quot;&quot;&quot;</span>
    <span class="token keyword">return</span> data<span class="token punctuation">[</span>data<span class="token punctuation">[</span><span class="token string">&#39;group&#39;</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">str</span><span class="token punctuation">.</span>contains<span class="token punctuation">(</span>categrot<span class="token punctuation">)</span><span class="token punctuation">]</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>最后只需要将返回的数据取个长度就可以得到每大类论文的数量。</p><p>然后，就可以开始编写代码构建 web应用 展示数据。</p><p>在这里我对比了 <code>pyecharts</code> 和 <code>plotly</code> 两个库的区别，结论是：</p><ul><li><code>pyecharts </code>动画交互效果好，交互功能齐全。毕竟有专业前端库 <code>Echarts</code> 的支持</li><li><code>pyecharts</code> 默认样式美观，<code>plotly</code> 需要自己调整样式</li><li><code>plotly</code> 代码编写简单，可以快速绘图但交互能力不好</li><li>在 <code>streamlit</code> 上 原生支持<code>plotly</code> 但 <code>pyecharts</code> 是第三方支持</li></ul><p>总的来说，我更倾向于使用 pyecharts。</p><h2 id="性能测试" tabindex="-1"><a class="header-anchor" href="#性能测试" aria-hidden="true">#</a> 性能测试</h2><p>在这过程中我发现每次运行代码时，总是需要等一段时间。</p><p>因为需要进行可视化交互，所以对于程序的运行速度有一定的要求。由于文件的数据量比较大，所以必须要想办法提高运行速度。</p><p>通过测试比较 <em>文件读取</em> 与 <em>数据计算</em> 的运行时间，发现程序运行时间主要消耗在 IO 上 ，然后通过修改文件格式为 pkl 成功提高读取数量。测试代码如下:</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
<span class="token keyword">import</span> time

start_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
data_csv <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">&#39;../arxiv-metadata-oai-2019.csv&#39;</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">&#39;id&#39;</span><span class="token punctuation">:</span> <span class="token string">&#39;str&#39;</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
end_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&#39;csv文件读取时间: &#39;</span><span class="token punctuation">,</span> end_time <span class="token operator">-</span> start_time<span class="token punctuation">)</span>

start_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
data_pkl <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_pickle<span class="token punctuation">(</span><span class="token string">&#39;../arxiv-metadata-oai-2019.pkl&#39;</span><span class="token punctuation">)</span>
end_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&#39;pkl文件读取时间: &#39;</span><span class="token punctuation">,</span> end_time <span class="token operator">-</span> start_time<span class="token punctuation">)</span>

start_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
data_csv<span class="token punctuation">.</span>groupby<span class="token punctuation">(</span><span class="token string">&#39;group&#39;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span>
end_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&#39;csv执行时间: &#39;</span><span class="token punctuation">,</span> end_time <span class="token operator">-</span> start_time<span class="token punctuation">)</span>

start_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
data_pkl<span class="token punctuation">.</span>groupby<span class="token punctuation">(</span><span class="token string">&#39;group&#39;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span>
end_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&#39;pkl执行时间: &#39;</span><span class="token punctuation">,</span> end_time <span class="token operator">-</span> start_time<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>输出：</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>csv文件读取时间:  3.394251585006714
pkl文件读取时间:  0.5429229736328125
csv执行时间:  0.009101390838623047
pkl执行时间:  0.008001327514648438
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>从上面不难看出</p><ol><li>文件读取占用大量时间</li><li>pkl 文件的读取速度相对于 csv 格式的快了将近 6 倍。</li></ol><h2 id="第二个目标-按月份统计每个月论文的提交数量" tabindex="-1"><a class="header-anchor" href="#第二个目标-按月份统计每个月论文的提交数量" aria-hidden="true">#</a> 第二个目标：按月份统计每个月论文的提交数量</h2><p>这个需求比较简单，我们发现数据中存在 <code>&quot;update_date&quot;: &quot;2019-08-19&quot;</code>所以我们只需要使用 <code>pandas</code> 将字符串类型转化为时间类型然后按月分组聚合求数量。这样我们就可以画出一个关于每月总论文数量的折线图，这样有点过于单调, 所以我们决定在绘制一个所有大类每月论文发表数量的 <em>气泡图</em> 以及 <em>区域叠加图</em> 。主要过程就是:</p><ol><li>使用上面函数选出大类数据</li><li>对月份分组聚合</li><li>转换为特定的数据格式</li><li>使用绘图库绘制图形</li><li>使用 <code>streamlit</code> 渲染成网页</li></ol><h2 id="第三个目标-论文摘要和论文标题出现关键词的频率" tabindex="-1"><a class="header-anchor" href="#第三个目标-论文摘要和论文标题出现关键词的频率" aria-hidden="true">#</a> 第三个目标：论文摘要和论文标题出现关键词的频率</h2><p>它们分别存储在 <code>&quot;title&quot;</code> 和 <code>&quot;abstract&quot;</code> 字段，两个字段都是字符串。而且是英文的，每个字符都用空格隔开所以需要处理按空格分离单词再统计单词个数。在这个过程中需要注意以下问题：</p><ul><li>需要先去除标点因为标点符号，因为标点符号和单词之间没有空格</li><li>需要全部转换为小写，因为有些单词是大写开头</li><li>需要剔除无意义词，比如：me、of、the</li></ul><p>在这里我发现程序执行完成需要一段时间。是因为数据量太多了，所以尝试修改代码。原先是取出一个单词先检查要不要剔除再统计，改为先统计所有单词再剔除无意义单词。这样就减少了大量与停词库比较的时间。但即使是这样，仍旧需要大量时间。但是程序已经没有优化的地方了。所以为了节省演示时间，我决定设置一下数据数量。其实，速度慢是 pandas 决定的，因为 pandas 是单核运行。所以需要加快速度需要使用多核并行的库，甚至是 <code>spark</code>等分布式技术。</p><p>最后根据关键字出现的次数构建词云图。</p><h2 id="第四个目标-论文更新次数" tabindex="-1"><a class="header-anchor" href="#第四个目标-论文更新次数" aria-hidden="true">#</a> 第四个目标：论文更新次数</h2><p>相关字段长这样</p><div class="language-json line-numbers-mode" data-ext="json"><pre class="language-json"><code><span class="token property">&quot;versions&quot;</span><span class="token operator">:</span> <span class="token punctuation">[</span>
    <span class="token punctuation">{</span>
      <span class="token property">&quot;version&quot;</span><span class="token operator">:</span> <span class="token string">&quot;v1&quot;</span><span class="token punctuation">,</span>
      <span class="token property">&quot;created&quot;</span><span class="token operator">:</span> <span class="token string">&quot;Tue, 3 Apr 2007 01:50:26 GMT&quot;</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">{</span>
      <span class="token property">&quot;version&quot;</span><span class="token operator">:</span> <span class="token string">&quot;v2&quot;</span><span class="token punctuation">,</span>
      <span class="token property">&quot;created&quot;</span><span class="token operator">:</span> <span class="token string">&quot;Wed, 4 Apr 2007 17:28:44 GMT&quot;</span>
    <span class="token punctuation">}</span>
  <span class="token punctuation">]</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>就是一个列表，只需要取列表长度就知道更新次数了。</p><p>处理过程：</p><ol><li>一样先用上面函数选出指定字段的数据</li><li>取列表长度</li><li>绘图</li></ol><p>绘制图片后发现数据主要集中在 1 、2、3 上所以设计了一个滚动条可以查看不同区间的数据图。</p><h2 id="第五个目标-论文作者关系图" tabindex="-1"><a class="header-anchor" href="#第五个目标-论文作者关系图" aria-hidden="true">#</a> 第五个目标：论文作者关系图</h2><p>相关字段有两个：</p><div class="language-json line-numbers-mode" data-ext="json"><pre class="language-json"><code>    <span class="token property">&quot;authors&quot;</span><span class="token operator">:</span> <span class="token string">&quot;Sung-Chul Yoon, Philipp Podsiadlowski and Stephan Rosswog&quot;</span>
    
    <span class="token property">&quot;authors_parsed&quot;</span><span class="token operator">:</span> <span class="token punctuation">[</span>
        <span class="token punctuation">[</span>
          <span class="token string">&quot;Yoon&quot;</span><span class="token punctuation">,</span>
          <span class="token string">&quot;Sung-Chul&quot;</span><span class="token punctuation">,</span>
          <span class="token string">&quot;&quot;</span>
        <span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">[</span>
          <span class="token string">&quot;Podsiadlowski&quot;</span><span class="token punctuation">,</span>
          <span class="token string">&quot;Philipp&quot;</span><span class="token punctuation">,</span>
          <span class="token string">&quot;&quot;</span>
        <span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">[</span>
          <span class="token string">&quot;Rosswog&quot;</span><span class="token punctuation">,</span>
          <span class="token string">&quot;Stephan&quot;</span><span class="token punctuation">,</span>
          <span class="token string">&quot;&quot;</span>
        <span class="token punctuation">]</span>
    <span class="token punctuation">]</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><code>&quot;authors&quot;</code>字符串结构的数据，需要处理一下，因为他虽然姓和名用空格分开每个人用逗号分隔。但是，他最后两个人名是用 and 连接的所以需要特殊判断耗时费力。所以，不用犹豫，果断选择 <code>&quot;authors_parsed&quot;</code>。只需要将每个列表拼接就可以形成人名，然后只需要遍历所有人名，看一下在其余论文中是否存在这个人就行。</p><p>本来想着自己写算法实现这个功能的，但是后面发现已经有现成的了，这就是 networkx 库。它可以帮我们快速找到连通图。自己写费时费力速度还不一定有别的快。一样，果断使用 networkx 实现。然后就是绘图。然后做了一些简单统计。</p><h2 id="第六个目标-作者的论文个数排行" tabindex="-1"><a class="header-anchor" href="#第六个目标-作者的论文个数排行" aria-hidden="true">#</a> 第六个目标：作者的论文个数排行</h2><p>选择 <code>&quot;submitter&quot;</code>作为论文的主要作者，然后按<code>submitter</code>字段分组聚合。</p><p>过程：</p><ol><li>使用上面函数选出大类数据</li><li>对提交者字段分组聚合</li><li>转换为特定的数据格式</li><li>使用绘图库绘制图形</li><li>使用 <code>streamlit</code> 渲染成网页</li></ol><p>为了数据美观，我将行列倒置然后加上颜色映射，即数量越高颜色越深。</p><h2 id="第七个目标-页数、图、表统计" tabindex="-1"><a class="header-anchor" href="#第七个目标-页数、图、表统计" aria-hidden="true">#</a> 第七个目标：页数、图、表统计</h2><p>相关字段：</p><div class="language-json line-numbers-mode" data-ext="json"><pre class="language-json"><code>  <span class="token property">&quot;comments&quot;</span><span class="token operator">:</span> &quot;<span class="token number">15</span> pages<span class="token punctuation">,</span> <span class="token number">15</span> figures<span class="token punctuation">,</span> <span class="token number">3</span> tables<span class="token punctuation">,</span> submitted to MNRAS (Low resolution\\n
  version; a high resolution version can be found at<span class="token operator">:</span>\\n
  http<span class="token operator">:</span><span class="token comment">//www.astro.uva.nl/~scyoon/papers/wdmerger.pdf)&quot;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>可以看到有 <code>15 pages, 15 figures, 3 tables</code> pages 前面的数字表示论文页数、figures 前面的数字表示 图的的个数、tables 前面的数字表示表的个数。</p><p>所以只需要使用正则表达式提取相关数据，然后求平均值绘制雷达图。</p><h2 id="项目部署" tabindex="-1"><a class="header-anchor" href="#项目部署" aria-hidden="true">#</a> 项目部署</h2><p>为了使得所有人都能访问项目，需要将项目迁移到云服务器中。主要就三步：</p><ol><li>申请云服务器（建议使用 Linux 操作系统）</li><li>安装环境</li><li>运行项目</li></ol><p>这里就不细说怎么做了，网上资源很多我们需要自己学会寻找有用信息。至于怎么使用 Linux 的话，网上教程也很多，我这里也有一些 <a href="/blogs/linux/%E5%88%9D%E8%AF%86linux">资料</a>。</p><h2 id="总结" tabindex="-1"><a class="header-anchor" href="#总结" aria-hidden="true">#</a> 总结</h2>`,50),R={href:"https://github.com/ma-yuan6/DataAnalysis/tree/master",target:"_blank",rel:"noopener noreferrer"};function L(B,G){const e=i("ExternalLinkIcon");return p(),l("div",null,[u,s("p",null,[s("a",r,[n("数据集和相关资料"),t(e)]),n("在这。")]),d,s("p",null,[n("发现给的 json 文件，格式比较乱。所以，使用 "),s("a",k,[n("json格式化工具"),t(e)]),n(" 格式化 json 后分析。")]),v,s("ul",null,[m,s("li",null,[h,n("：数字对象标识符，"),s("a",b,[n("https://www.doi.org"),t(e)])]),g]),s("p",null,[n("对 "),q,n(" 的说明，查询 "),s("a",y,[n("这个网站"),t(e)]),n(" 发现 arXiv 将论文分为"),_,n("(计算机科学)、"),f,n("(经济学)、"),w,n("(电气工程与系统科学) "),x,n("(数学)、"),j,n("(物理)、"),S,n("(定量生物学)、"),P,n("(定量金融)、"),C,n("（统计学）8个大类，里面又包含多个小类。因为数量过多，所以为了快速获取全部信息决定使用爬虫获取数据。")]),A,s("p",null,[n("首先我们爬取了"),s("a",T,[n("这个网站"),t(e)]),n(" 的数据。得到了每个小类和大类的对照表，依据源数据 "),M,n(" 我们可以在对照表中找到对应的大类。然后使用 "),E,n(" 连接函数在原来数据的基础上加上了 'group' 字段, 表示每篇论文的大类。但是我们发现并不， 每篇论文只对应一种大类。给的参考代码上是选择第一个类别, 但我们觉得这样不合适，所以决定所有类别都要。因此需要设计一个函数选出包含特定大类的所有数据：")]),O,s("p",null,[n("这项目我已经放入 Github 中，"),s("a",R,[n("地址在这"),t(e)]),n("。由于就只有两周时间所以做的还是有点简单，后续我还会改进一下加上配置和日志功能。如果有时间的话还会考虑使用 Spark 重写其中部分功能。")])])}const N=o(c,[["render",L],["__file","Pythonshujufenxi.html.vue"]]);export{N as default};
